# ğŸ§  3D Video Generator using Depth Estimation

This project generates 3D videos from 2D input videos by performing **depth estimation** and **stereo image generation** using deep learning models like MiDaS and Transformer-based architectures.

---

## ğŸ“½ï¸ Features

- Extract frames from an input video
- Estimate depth maps using a pre-trained MiDaS model
- Generate stereo left-right views to simulate 3D perspective
- Combine stereo frames into a final 3D video
- Output in `.mp4` format

---

## ğŸ› ï¸ Tech Stack

- Python 3.10+
- OpenCV
- PyTorch
- TensorFlow
- Transformers (HuggingFace)
- NumPy

---

## ğŸ“¦ Setup

### 1. Clone the Repository
```bash
git clone https://github.com/manojdakuwa/3D_VideoConverting.git
cd 3d-video-generator
python -m venv depth_env
source depth_env/bin/activate  # On Windows: depth_env\Scripts\activate
python -m venv depth_env
source depth_env/bin/activate  # On Windows: depth_env\Scripts\activate
pip install -r requirements.txt

3d-video-generator/
â”‚
â”œâ”€â”€ data/                     # Input videos
â”œâ”€â”€ output/                   # Output 3D videos
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ video_processing.py   # Frame extraction
â”‚   â”œâ”€â”€ depth_estimation.py   # MiDaS model loading and prediction
â”‚   â”œâ”€â”€ stereo_conversion.py  # Stereo image generation
â”‚   â””â”€â”€ video_output.py       # Output 3D video writer
â”‚
â”œâ”€â”€ main.py                   # Main pipeline
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

python main.py


âš ï¸ Notes
Make sure numpy version is compatible with TensorFlow (<2.2.0)

You may need to adjust frame resolution or video codec based on your system

Tested with MiDaS (Intel/dpt-hybrid-midas) from Hugging Face

